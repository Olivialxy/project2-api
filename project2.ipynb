{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Web Scraping and API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Explore the html for Wikipedia articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Using inspect element, copy the html code for a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table {\n",
    "    display: table;\n",
    "    border-collapse: separate;\n",
    "    box-sizing: border-box;\n",
    "    text-indent: initial;\n",
    "    unicode-bidi: isolate;\n",
    "    width: max-content;\n",
    "    min-width: 100vw;\n",
    "    font-size: initial;\n",
    "    font-family: monospace;\n",
    "    tab-size: 4;\n",
    "    border-spacing: 0px;\n",
    "    border-color: gray;\n",
    "    white-space: pre;\n",
    "    margin: 0px;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Using inspect element, find the html syntax for a link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a class=\"vector-toc-link\" href=\"#Scope_and_approach\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Using inspect element, find the html syntax for linking an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"mw-logo-icon\" src=\"/static/images/icons/wikipedia.png\" alt=\"\" aria-hidden=\"true\" height=\"50\" width=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Explore one Wikipedia page with the beautifulsoup package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save and print the text content of a page with all tags removed\n",
    "url = \"https://en.wikipedia.org/wiki/Information_science\"  \n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "text_content = soup.get_text()\n",
    "print(text_content[:1000])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download an image with beautifulsoup and save it in this repository\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Bibliometrics_definition.svg/440px-Bibliometrics_definition.svg.png\"\n",
    "image_response = requests.get(image_url)\n",
    "with open(\"downloaded_image.jpg\", 'wb') as file:\n",
    "    file.write(image_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all the links in a page with beautifulsoup\n",
    "#print the first 100 characters of ten of these links\n",
    "links = soup.find_all('a')\n",
    "for link in links[:10]:  \n",
    "    print(str(link.get('href'))[:100])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Downloading scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts=pd.read_csv('pudding_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the links in the \"link\" column, download the first 1000 characters of each script\n",
    "#use requests and bs4, remember to remove all html tags\n",
    "def download_script_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text = soup.get_text()  \n",
    "    return text[:1000]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new column to the df with the text downloaded\n",
    "#save this new dataframe as \"pudding_texts.csv\"\n",
    "scripts['script_text'] = scripts['link'].apply(download_script_text)\n",
    "scripts.to_csv('pudding_texts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: TMDB database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse the documentation at https://developer.themoviedb.org/reference/intro/getting-started. Create an account to authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset of the movies in theaters now. Include metadata fields you are interested in. \n",
    "# Create a dataset of the movies in theaters now using TMDB API\n",
    "api_key = \"d7741d3e395a5c77addf43f0321a8305\"  \n",
    "url = f\"https://api.themoviedb.org/3/movie/now_playing?api_key={api_key}&language=en-US&page=1\"\n",
    "response = requests.get(url)\n",
    "movies_data = response.json()['results']\n",
    "\n",
    "movies = []\n",
    "for movie in movies_data:\n",
    "    movies.append({\n",
    "        'title': movie['title'],\n",
    "        'release_date': movie['release_date'],\n",
    "        'vote_average': movie['vote_average'],\n",
    "        'overview': movie['overview'],\n",
    "        'poster_path': f\"https://image.tmdb.org/t/p/w500{movie['poster_path']}\"  # Poster URL\n",
    "    })\n",
    "\n",
    "movies_df = pd.DataFrame(movies)\n",
    "movies_df.to_csv('movies_in_theaters_now.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the movie posters for 10 of these movies and save them to this repository\n",
    "for i, movie in enumerate(movies[:10]):\n",
    "    poster_url = movie['poster_path']\n",
    "    poster_response = requests.get(poster_url)\n",
    "    \n",
    "    with open(f\"poster_{i+1}.jpg\", 'wb') as file:\n",
    "        file.write(poster_response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
